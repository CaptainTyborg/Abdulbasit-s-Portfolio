{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNDzx8kZNHbOybdh8Vf+IOx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaptainTyborg/Abdulbasit-s-Portfolio/blob/main/Week_3_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WVm58nEhRw2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b1c8293"
      },
      "source": [
        "# Task\n",
        "Build a Convolutional Neural Network (CNN) model using either TensorFlow or PyTorch to classify handwritten digits from the MNIST dataset. Define the model architecture and compile it with an appropriate optimizer and loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc0a21df"
      },
      "source": [
        "## Part 1: Theoretical Understanding - Short Answer Questions\n",
        "\n",
        "### Subtask:\n",
        "Address the short answer questions: Q1 (TensorFlow vs. PyTorch), Q2 (Jupyter Notebook use cases), and Q3 (spaCy vs. Python string operations for NLP).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd2b2cb3"
      },
      "source": [
        "## Part 1: Theoretical Understanding - Short Answer Questions\n",
        "\n",
        "### Q1: TensorFlow vs. PyTorch\n",
        "\n",
        "**TensorFlow** and **PyTorch** are both powerful open-source machine learning frameworks, but they have distinct philosophies and features:\n",
        "\n",
        "*   **API Design:**\n",
        "    *   **TensorFlow:** Traditionally had a more complex and verbose API (especially TensorFlow 1.x), often requiring a steeper learning curve. TensorFlow 2.x introduced a more user-friendly Keras-like API, making it more accessible.\n",
        "    *   **PyTorch:** Known for its Pythonic and intuitive API, which feels more natural to Python developers. It is often praised for its ease of use and flexibility.\n",
        "\n",
        "*   **Computation Graph (Static vs. Dynamic):**\n",
        "    *   **TensorFlow:** Historically used a **static computation graph**. This means the entire graph structure must be defined before execution. While this allows for powerful optimizations and deployment to various platforms, debugging can be harder as the graph is not built on-the-fly.\n",
        "    *   **PyTorch:** Employs a **dynamic computation graph** (also known as \"define-by-run\"). The graph is built as operations are executed, similar to how regular Python code runs. This makes debugging much easier and allows for more flexible model architectures, especially those with variable-length inputs or control flow.\n",
        "\n",
        "*   **Community and Ecosystem:**\n",
        "    *   **TensorFlow:** Backed by Google, it has a massive and mature ecosystem with extensive tools for production deployment (TensorFlow Extended - TFX, TensorFlow Serving, TensorFlow Lite). It's widely adopted in industry for large-scale deployments.\n",
        "    *   **PyTorch:** Backed by Facebook (Meta AI), it has gained significant traction in the research community due to its flexibility and ease of prototyping. Its ecosystem is rapidly growing, especially with libraries like PyTorch Lightning for streamlined training and TorchServe for deployment.\n",
        "\n",
        "*   **Typical Use Cases:**\n",
        "    *   **TensorFlow:** Often preferred for large-scale production deployments, especially in enterprises that require robust infrastructure, mobile/edge device deployment, and distributed training. Its strong tooling for production makes it a go-to for many industry applications.\n",
        "    *   **PyTorch:** Dominant in academic research and rapid prototyping. Its dynamic graph and Pythonic nature make it excellent for experimentation, complex model development, and scenarios where model architecture might change frequently during development.\n",
        "\n",
        "### Q2: Jupyter Notebook Use Cases\n",
        "\n",
        "Jupyter Notebooks are incredibly versatile and are widely used across various fields due to their interactive and documentation capabilities. Here are several key use cases:\n",
        "\n",
        "1.  **Data Exploration and Cleaning:** Data scientists often use notebooks to load datasets, perform initial exploratory data analysis (EDA) with visualizations, identify missing values, outliers, and data types, and then write code to clean and preprocess the data. The ability to see immediate results after each step is invaluable.\n",
        "2.  **Statistical Modeling and Machine Learning Prototyping:** They are ideal for developing and experimenting with statistical models and machine learning algorithms. Users can iteratively build models, train them on small subsets of data, evaluate performance, and adjust parameters, all within the same document that includes explanations and results.\n",
        "3.  **Data Visualization:** Jupyter notebooks excel at creating and displaying interactive data visualizations (e.g., with Matplotlib, Seaborn, Plotly). The output of plotting code is immediately visible below the cell, allowing for quick adjustments and clear presentation of insights.\n",
        "4.  **Reporting and Storytelling:** A major strength of Jupyter is its ability to combine code, output (tables, plots, images), and descriptive text (markdown) into a single, cohesive document. This makes them excellent for creating reproducible research papers, project reports, and tutorials, effectively telling a data story from start to finish.\n",
        "5.  **Teaching and Learning:** Their interactive nature makes them a popular tool for educational purposes. Instructors can share notebooks containing lecture notes, code examples, and exercises, allowing students to execute code, modify it, and see results in real-time.\n",
        "6.  **Collaborative Work:** Notebooks can be easily shared and version-controlled (e.g., via Git), facilitating collaboration among data scientists, researchers, and engineers. Platforms like JupyterHub and Google Colab further enhance collaborative environments.\n",
        "7.  **Software Development (Exploratory):** While not a full-fledged IDE, notebooks can be used for exploratory software development, especially when testing out new libraries, APIs, or algorithms in an isolated and interactive environment.\n",
        "\n",
        "### Q3: spaCy vs. Python String Operations for NLP\n",
        "\n",
        "Comparing **spaCy** with standard Python string operations for Natural Language Processing (NLP) tasks reveals significant differences in efficiency, accuracy, and capabilities:\n",
        "\n",
        "*   **Efficiency:**\n",
        "    *   **Python String Operations:** When performing NLP tasks using basic Python string methods (e.g., `split()`, `replace()`, `lower()`, `find()`), you often end up writing custom, manual parsing logic. This can be very inefficient for large texts and complex operations, as these methods are not optimized for linguistic processing.\n",
        "    *   **spaCy:** Designed for production use and efficiency. It is written in Cython and uses highly optimized data structures and algorithms. For example, tokenization, lemmatization, and dependency parsing are executed much faster in spaCy than if one were to try to implement them from scratch using pure Python strings.\n",
        "\n",
        "*   **Accuracy:**\n",
        "    *   **Python String Operations:** Basic string operations lack linguistic intelligence. For instance, splitting text by spaces might incorrectly handle punctuation or contractions. Lemmatization (reducing words to their base form) or part-of-speech tagging is impossible to achieve accurately with simple string methods without complex, error-prone rule-based systems.\n",
        "    *   **spaCy:** Provides highly accurate, pre-trained statistical models for various languages. These models can perform tasks like tokenization, part-of-speech tagging, named entity recognition, dependency parsing, and more with state-of-the-art accuracy. It understands linguistic context, which significantly improves the quality of NLP results.\n",
        "\n",
        "*   **Capabilities:**\n",
        "    *   **Python String Operations:** Limited to basic text manipulation (e.g., searching for substrings, changing case, splitting by delimiters). It doesn't inherently understand words, sentences, or grammatical structures.\n",
        "    *   **spaCy:** Offers a rich suite of advanced NLP capabilities out-of-the-box:\n",
        "        *   **Tokenization:** Intelligent splitting of text into words, punctuation, etc., handling edge cases like contractions.\n",
        "        *   **Lemmatization:** Reducing words to their base form (e.g., \"running\" -> \"run\").\n",
        "        *   **Part-of-Speech Tagging:** Identifying the grammatical role of each word (noun, verb, adjective, etc.).\n",
        "        *   **Named Entity Recognition (NER):** Identifying and classifying named entities (people, organizations, locations, dates).\n",
        "        *   **Dependency Parsing:** Revealing the grammatical structure of sentences by showing relationships between words.\n",
        "        *   **Word Vectors/Embeddings:** Access to pre-trained word embeddings for semantic similarity and other tasks.\n",
        "        *   **Rule-based Matching:** Powerful pattern matching for identifying specific sequences of tokens.\n",
        "\n",
        "In summary, while Python string operations are foundational for basic text handling, **spaCy** provides a sophisticated, efficient, and accurate framework built specifically for complex NLP tasks. It abstracts away the linguistic complexities, allowing developers to focus on higher-level applications rather than re-implementing fundamental NLP components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4810ff21"
      },
      "source": [
        "## Part 1: Theoretical Understanding - Comparative Analysis\n",
        "\n",
        "### Subtask:\n",
        "Compare Scikit-learn and TensorFlow based on their target applications (classical ML vs. deep learning), ease of use for beginners, and community support.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cdd8076"
      },
      "source": [
        "```markdown\n",
        "## Comparing Scikit-learn and TensorFlow\n",
        "\n",
        "### 1. Target Applications (Classical ML vs. Deep Learning)\n",
        "\n",
        "*   **Scikit-learn:** Primarily designed for **classical machine learning** tasks. It provides a wide range of algorithms for supervised and unsupervised learning, including classification, regression, clustering, dimensionality reduction, and model selection. It is excellent for structured data and traditional statistical modeling where interpretability is often key.\n",
        "\n",
        "*   **TensorFlow:** Built for **deep learning** and neural networks. It excels in tasks involving large, unstructured datasets like images, text, and audio. It supports complex neural network architectures, including Convolutional Neural Networks (CNNs) for image processing, Recurrent Neural Networks (RNNs) for sequential data, and Transformers for natural language processing.\n",
        "\n",
        "### 2. Ease of Use for Beginners\n",
        "\n",
        "*   **Scikit-learn:** Generally considered **easier for beginners**. Its API is consistent and intuitive across different algorithms, following a `fit()` and `predict()` pattern. It's well-documented with numerous examples, making it straightforward to implement and experiment with classical ML models without extensive mathematical or programming overhead.\n",
        "\n",
        "*   **TensorFlow:** Can be **more challenging for beginners**, especially when starting with raw TensorFlow. While high-level APIs like Keras (now integrated into TensorFlow) have significantly improved its user-friendliness, understanding concepts like computational graphs, tensors, and different layers still requires a steeper learning curve. Setting up custom models and handling data pipelines can be more complex.\n",
        "\n",
        "### 3. Community Support\n",
        "\n",
        "*   **Scikit-learn:** Boasts a **large and active community**, particularly among data scientists and ML practitioners focused on classical algorithms. It has extensive documentation, numerous tutorials, and a strong presence on platforms like Stack Overflow. Its stable and mature codebase ensures reliable support.\n",
        "\n",
        "*   **TensorFlow:** Possesses an **enormous and very active global community**, backed by Google. It has comprehensive official documentation, a vast array of tutorials, courses, and research papers. Being at the forefront of deep learning research, its community is constantly pushing boundaries and providing support for cutting-edge techniques. However, due to its rapid evolution, older resources might sometimes be outdated.\n",
        "\n",
        "In summary, Scikit-learn is the go-to for traditional ML and provides a gentle entry point, while TensorFlow is the powerhouse for deep learning, offering immense flexibility and scalability at the cost of initial complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec4edbd2"
      },
      "source": [
        "## Part 2: Practical Implementation - Task 1: Classical ML with Scikit-learn (Data Preprocessing)\n",
        "\n",
        "### Subtask:\n",
        "Load the Iris Species Dataset. Preprocess the data, which includes checking for and handling any missing values, and encoding the target labels if necessary. This will prepare the data for model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90627b6a"
      },
      "source": [
        "**Reasoning**:\n",
        "Verify the successful loading of the Iris dataset, check for any missing values in the features (X) and target labels (y), and confirm if the target labels are already in a numerical format suitable for Scikit-learn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8961310",
        "outputId": "a9ddcf5f-e5e2-485e-8294-750d2dbec26e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Verify that the Iris dataset (features in X and target labels in y) has been successfully loaded.\n",
        "print(\"Shape of X (features):\", X.shape)\n",
        "print(\"Shape of y (target labels):\", y.shape)\n",
        "print(\"First 5 rows of X:\\n\", X[:5])\n",
        "print(\"First 5 elements of y:\\n\", y[:5])\n",
        "\n",
        "# 2. Check for any missing values in the features (X) and target labels (y).\n",
        "missing_in_X = np.isnan(X).sum()\n",
        "missing_in_y = np.isnan(y).sum()\n",
        "\n",
        "print(f\"\\nMissing values in X: {missing_in_X}\")\n",
        "print(f\"Missing values in y: {missing_in_y}\")\n",
        "\n",
        "# 3. Examine the y variable to determine if the target labels are already in a numerical format.\n",
        "print(f\"\\nData type of y: {y.dtype}\")\n",
        "print(f\"Unique values in y: {np.unique(y)}\")\n",
        "\n",
        "if y.dtype == np.int64 or y.dtype == np.int32:\n",
        "    print(\"Target labels (y) are already in a numerical format. No encoding is necessary.\")\n",
        "else:\n",
        "    print(\"Target labels (y) are not in a numerical format. Label encoding might be required.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X (features): (150, 4)\n",
            "Shape of y (target labels): (150,)\n",
            "First 5 rows of X:\n",
            " [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "First 5 elements of y:\n",
            " [0 0 0 0 0]\n",
            "\n",
            "Missing values in X: 0\n",
            "Missing values in y: 0\n",
            "\n",
            "Data type of y: int64\n",
            "Unique values in y: [0 1 2]\n",
            "Target labels (y) are already in a numerical format. No encoding is necessary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7957a147"
      },
      "source": [
        "## Part 2: Practical Implementation - Task 1: Classical ML with Scikit-learn (Model Training & Evaluation)\n",
        "\n",
        "### Subtask:\n",
        "Train a Decision Tree Classifier on the preprocessed Iris dataset using Scikit-learn and evaluate its performance using accuracy, precision, and recall metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "670e72ec"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires printing the calculated accuracy, precision, and recall scores. These metrics have already been computed in a previous step and are available in the kernel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ca1d531",
        "outputId": "ba567e0d-a4c1-46ab-ff77-f6aa725c3343"
      },
      "source": [
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1f41308"
      },
      "source": [
        "## Part 2: Practical Implementation - Task 2: Deep Learning with TensorFlow/PyTorch (CNN Model Building)\n",
        "\n",
        "### Subtask:\n",
        "Load the MNIST Handwritten Digits dataset, build a Convolutional Neural Network (CNN) model using TensorFlow, define its architecture, and compile it with an appropriate optimizer and loss function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36153ff7"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires loading the MNIST dataset, preprocessing it, defining a Convolutional Neural Network (CNN) model using TensorFlow/Keras, and compiling it with an appropriate optimizer and loss function. This `code_block` will perform all these steps sequentially.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "b51790f6",
        "outputId": "fea2f447-cf48-40ba-bcc8-c812dde13f1c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1. Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. Normalize and reshape the image data\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Reshape data to add a channel dimension (for CNN input)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# 3. Build a Sequential CNN model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)), # Input layer specifying the input shape\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5), # Dropout for regularization to prevent overfitting\n",
        "        layers.Dense(100, activation=\"relu\"), # Hidden dense layer\n",
        "        layers.Dense(10, activation=\"softmax\"), # Output layer with 10 units for 10 digits\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nCNN Model Summary:\")\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "\n",
            "CNN Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m160,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,926\u001b[0m (702.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,926</span> (702.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,926\u001b[0m (702.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,926</span> (702.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9a85f86"
      },
      "source": [
        "## Part 2: Practical Implementation - Task 2: Deep Learning with TensorFlow/PyTorch (Model Training & Visualization)\n",
        "\n",
        "### Subtask:\n",
        "Train the CNN model on the MNIST dataset, aiming for greater than 95% test accuracy. After training, visualize the model's predictions on 5 sample images from the test set to demonstrate its performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb0c580a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires training the previously defined CNN model, then selecting 5 random sample images from the test set, predicting their labels, and finally visualizing each image along with its true and predicted label. This code block will perform all these steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "df3e6e21",
        "outputId": "9870c275-7f4a-4efe-b8ea-3402af69945b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
        "\n",
        "# 2. Select 5 random sample images and their true labels\n",
        "num_samples = 5\n",
        "random_indices = np.random.choice(x_test.shape[0], num_samples, replace=False)\n",
        "\n",
        "sample_images = x_test[random_indices]\n",
        "sample_true_labels = y_test[random_indices]\n",
        "\n",
        "# 3. Use the trained model to predict the digit for each sample image\n",
        "sample_predictions = model.predict(sample_images)\n",
        "sample_predicted_labels = np.argmax(sample_predictions, axis=1)\n",
        "\n",
        "# 4. Visualize and print for each sample image\n",
        "print(\"\\n--- Model Predictions on Sample Images ---\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(1, num_samples, i + 1)\n",
        "    plt.imshow(sample_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"True: {sample_true_labels[i]}\\nPred: {sample_predicted_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model's performance on the test set to check accuracy requirement\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "if accuracy * 100 > 95:\n",
        "    print(\"Target accuracy of greater than 95% achieved!\")\n",
        "else:\n",
        "    print(\"Target accuracy of greater than 95% not yet achieved.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 68ms/step - accuracy: 0.8269 - loss: 0.5813 - val_accuracy: 0.9798 - val_loss: 0.0670\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.9722 - loss: 0.0894 - val_accuracy: 0.9867 - val_loss: 0.0434\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 65ms/step - accuracy: 0.9802 - loss: 0.0636 - val_accuracy: 0.9883 - val_loss: 0.0328\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9837 - loss: 0.0546 - val_accuracy: 0.9906 - val_loss: 0.0285\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 65ms/step - accuracy: 0.9866 - loss: 0.0438 - val_accuracy: 0.9903 - val_loss: 0.0258\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 66ms/step - accuracy: 0.9891 - loss: 0.0350 - val_accuracy: 0.9920 - val_loss: 0.0239\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.9891 - loss: 0.0335 - val_accuracy: 0.9914 - val_loss: 0.0237\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 65ms/step - accuracy: 0.9901 - loss: 0.0315 - val_accuracy: 0.9918 - val_loss: 0.0242\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 67ms/step - accuracy: 0.9920 - loss: 0.0252 - val_accuracy: 0.9932 - val_loss: 0.0217\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.9931 - loss: 0.0236 - val_accuracy: 0.9924 - val_loss: 0.0213\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
            "\n",
            "--- Model Predictions on Sample Images ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 99.24%\n",
            "Target accuracy of greater than 95% achieved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "PIAVvtFUMah7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I bought the Samsung Galaxy phone and it works amazingly well.\"\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "W_OSHdw7MkcI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-qthszvMsl2",
        "outputId": "7333616a-08c2-4d04-cac7-20d522111409"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samsung Galaxy ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words = [\"good\", \"great\", \"amazing\", \"excellent\"]\n",
        "negative_words = [\"bad\", \"poor\", \"terrible\"]\n",
        "\n",
        "sentiment = \"Neutral\"\n",
        "for word in positive_words:\n",
        "    if word in text.lower():\n",
        "        sentiment = \"Positive\"\n",
        "\n",
        "for word in negative_words:\n",
        "    if word in text.lower():\n",
        "        sentiment = \"Negative\"\n",
        "\n",
        "print(\"Sentiment:\", sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioEPRQBrMzWJ",
        "outputId": "811914fe-61ef-40f5-ecd6-6b79b68dd6d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hIXm0pHN3MU",
        "outputId": "4c812951-8f7f-46c9-c102-6c82af92068c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "b-MLs0-HObqV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4948300f"
      },
      "source": [
        "# Task\n",
        "Create a Streamlit application that uses the previously trained CNN model to classify handwritten digits. Include the application code in a file named `app.py` and generate a `requirements.txt` file. Then, provide instructions to deploy this application to Streamlit Cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ea5f3d2"
      },
      "source": [
        "## Create Streamlit Application File\n",
        "\n",
        "### Subtask:\n",
        "Create a Python file (e.g., `app.py`) that contains all the code necessary to run your Streamlit application, including model loading and prediction logic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e03556c"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I need to save the trained Keras model as an HDF5 file so it can be loaded later by the Streamlit application. This is a prerequisite for creating the `app.py` file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "0c8098ec",
        "outputId": "540c201c-1115-43d0-ed5c-30fe6d2fc2c5"
      },
      "source": [
        "model.save('mnist_cnn_model.h5')\n",
        "print(\"Model saved as mnist_cnn_model.h5\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2400522432.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_cnn_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved as mnist_cnn_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87b050bd"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` occurred because the `model` object was not defined in the current kernel session due to prior cells not being executed. To fix this, the code block must redefine, compile, and train the CNN model before attempting to save it, as instructed to save the *trained* model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92d61ee4",
        "outputId": "7f7ebb17-e300-418b-8d29-ad8fcc826001"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. Normalize and reshape the image data\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Reshape data to add a channel dimension (for CNN input)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# 3. Build a Sequential CNN model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)), # Input layer specifying the input shape\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5), # Dropout for regularization to prevent overfitting\n",
        "        layers.Dense(100, activation=\"relu\"), # Hidden dense layer\n",
        "        layers.Dense(10, activation=\"softmax\"), # Output layer with 10 units for 10 digits\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 5. Train the model (re-executing the training step to ensure 'model' is trained)\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test), verbose=0)\n",
        "\n",
        "# 6. Save the trained model\n",
        "model.save('mnist_cnn_model.h5')\n",
        "print(\"Model saved as mnist_cnn_model.h5\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as mnist_cnn_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9f333e8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully saved the trained model. Now, as per the instructions, I need to create the `app.py` file which will contain the Streamlit application code, including model loading, image processing, and prediction logic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c410c8b0",
        "outputId": "bbedad6f-025f-4893-e4ba-9891a1dcb99b"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# 1. Load the trained Keras model\n",
        "# Ensure the model file 'mnist_cnn_model.h5' is in the same directory as app.py\n",
        "@st.cache_resource # Cache the model to avoid reloading it on every rerun\n",
        "def load_my_model():\n",
        "    model = load_model('mnist_cnn_model.h5')\n",
        "    return model\n",
        "\n",
        "model = load_my_model()\n",
        "\n",
        "# Streamlit app title and description\n",
        "st.title(\"MNIST Digit Classifier\")\n",
        "st.write(\"Upload a handwritten digit image, and the model will predict the digit.\")\n",
        "\n",
        "# File uploader widget\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    try:\n",
        "        # Read the image file\n",
        "        image = Image.open(uploaded_file).convert('L') # Convert to grayscale\n",
        "        st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "        st.write(\"\")\n",
        "\n",
        "        # Preprocess the image for the model\n",
        "        # Resize to 28x28\n",
        "        image = image.resize((28, 28))\n",
        "        # Convert to numpy array and normalize\n",
        "        image_array = np.array(image).astype('float32') / 255\n",
        "        # Reshape to (1, 28, 28, 1) to match model input\n",
        "        image_array = image_array.reshape(1, 28, 28, 1)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(image_array)\n",
        "        predicted_digit = np.argmax(prediction)\n",
        "\n",
        "        st.success(f\"Predicted Digit: {predicted_digit}\")\n",
        "        st.subheader(\"Prediction Probabilities:\")\n",
        "        # Display probabilities for each digit\n",
        "        for i, prob in enumerate(prediction[0]):\n",
        "            st.write(f\"Digit {i}: {prob*100:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error processing image: {e}\")\n",
        "        st.info(\"Please ensure the uploaded file is a valid image (png, jpg, jpeg).\")\n",
        "else:\n",
        "    st.info(\"Please upload an image to get a prediction.\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec52d7ba"
      },
      "source": [
        "## Create Requirements File\n",
        "\n",
        "### Subtask:\n",
        "Generate a `requirements.txt` file listing all the Python libraries and their versions that your Streamlit application depends on (e.g., `streamlit`, `tensorflow`, `numpy`, `matplotlib`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a142a81b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to generate a `requirements.txt` file that lists all the Python libraries and their versions used in the Streamlit application and model creation process. I will use `pip freeze` to capture these dependencies from the current environment and save them to a file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3944f4",
        "outputId": "ebd4cf03-aa93-4e6b-a900-4bf21ff0d0c7"
      },
      "source": [
        "%%bash\n",
        "pip freeze > requirements.txt\n",
        "\n",
        "echo \"Content of requirements.txt:\"\n",
        "cat requirements.txt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of requirements.txt:\n",
            "absl-py==1.4.0\n",
            "accelerate==1.12.0\n",
            "access==1.1.10.post3\n",
            "affine==2.4.0\n",
            "aiofiles==24.1.0\n",
            "aiohappyeyeballs==2.6.1\n",
            "aiohttp==3.13.2\n",
            "aiosignal==1.4.0\n",
            "aiosqlite==0.22.0\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.24\n",
            "albumentations==2.0.8\n",
            "ale-py==0.11.2\n",
            "alembic==1.17.2\n",
            "altair==5.5.0\n",
            "annotated-doc==0.0.4\n",
            "annotated-types==0.7.0\n",
            "antlr4-python3-runtime==4.9.3\n",
            "anyio==4.12.0\n",
            "anywidget==0.9.21\n",
            "argon2-cffi==25.1.0\n",
            "argon2-cffi-bindings==25.1.0\n",
            "array_record==0.8.3\n",
            "arrow==1.4.0\n",
            "arviz==0.22.0\n",
            "astropy==7.2.0\n",
            "astropy-iers-data==0.2025.12.15.0.40.51\n",
            "astunparse==1.6.3\n",
            "atpublic==5.1\n",
            "attrs==25.4.0\n",
            "audioread==3.1.0\n",
            "Authlib==1.6.6\n",
            "autograd==1.8.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "beartype==0.22.9\n",
            "beautifulsoup4==4.13.5\n",
            "betterproto==2.0.0b6\n",
            "bigframes==2.30.0\n",
            "bigquery-magics==0.10.3\n",
            "bleach==6.3.0\n",
            "blinker==1.9.0\n",
            "blis==1.3.3\n",
            "blobfile==3.1.0\n",
            "blosc2==3.12.2\n",
            "bokeh==3.7.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.45\n",
            "branca==0.8.2\n",
            "brotli==1.2.0\n",
            "CacheControl==0.14.4\n",
            "cachetools==6.2.4\n",
            "catalogue==2.0.10\n",
            "certifi==2025.11.12\n",
            "cffi==2.0.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.4\n",
            "chex==0.1.90\n",
            "clarabel==0.11.1\n",
            "click==8.3.1\n",
            "click-plugins==1.1.1.2\n",
            "cligj==0.7.2\n",
            "cloudpathlib==0.23.0\n",
            "cloudpickle==3.1.2\n",
            "cmake==3.31.10\n",
            "cmdstanpy==1.3.0\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.7\n",
            "contourpy==1.3.3\n",
            "cramjam==2.11.0\n",
            "cryptography==43.0.3\n",
            "cufflinks==0.17.3\n",
            "curl_cffi==0.13.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.7\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.13\n",
            "Cython==3.0.12\n",
            "dask==2025.12.0\n",
            "dataproc-spark-connect==1.0.1\n",
            "datasets==4.0.0\n",
            "db-dtypes==1.4.4\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.15\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "deprecation==2.1.0\n",
            "diffusers==0.36.0\n",
            "dill==0.3.8\n",
            "distro==1.9.0\n",
            "dlib==19.24.6\n",
            "dm-tree==0.1.9\n",
            "docstring_parser==0.17.0\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.3.2\n",
            "earthengine-api==1.5.24\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.2\n",
            "einops==0.8.1\n",
            "en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
            "entrypoints==0.4\n",
            "esda==2.8.0\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.13.0\n",
            "etuples==0.3.10\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.8.6\n",
            "fastapi==0.123.10\n",
            "fastcore==1.9.2\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.2\n",
            "fastprogress==1.0.3\n",
            "fasttransform==0.0.2\n",
            "ffmpy==1.0.0\n",
            "filelock==3.20.0\n",
            "fiona==1.10.1\n",
            "firebase-admin==6.9.0\n",
            "Flask==3.1.2\n",
            "flatbuffers==25.9.23\n",
            "flax==0.10.7\n",
            "folium==0.20.0\n",
            "fonttools==4.61.1\n",
            "fqdn==1.5.1\n",
            "frozendict==2.4.7\n",
            "frozenlist==1.8.0\n",
            "fsspec==2025.3.0\n",
            "future==1.0.0\n",
            "gast==0.7.0\n",
            "gcsfs==2025.3.0\n",
            "GDAL==3.8.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.1\n",
            "geopandas==1.1.1\n",
            "geopy==2.4.1\n",
            "giddy==2.3.8\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.45\n",
            "glob2==0.7\n",
            "google==3.0.0\n",
            "google-adk==1.21.0\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.28.1\n",
            "google-api-python-client==2.187.0\n",
            "google-auth==2.43.0\n",
            "google-auth-httplib2==0.2.1\n",
            "google-auth-oauthlib==1.2.2\n",
            "google-cloud-aiplatform==1.130.0\n",
            "google-cloud-appengine-logging==1.7.0\n",
            "google-cloud-audit-log==0.4.0\n",
            "google-cloud-bigquery==3.38.0\n",
            "google-cloud-bigquery-connection==1.19.0\n",
            "google-cloud-bigquery-storage==2.35.0\n",
            "google-cloud-bigtable==2.34.0\n",
            "google-cloud-core==2.5.0\n",
            "google-cloud-dataproc==5.23.0\n",
            "google-cloud-datastore==2.21.0\n",
            "google-cloud-discoveryengine==0.13.12\n",
            "google-cloud-firestore==2.21.0\n",
            "google-cloud-functions==1.21.0\n",
            "google-cloud-language==2.18.0\n",
            "google-cloud-logging==3.12.1\n",
            "google-cloud-monitoring==2.28.0\n",
            "google-cloud-resource-manager==1.15.0\n",
            "google-cloud-secret-manager==2.25.0\n",
            "google-cloud-spanner==3.60.0\n",
            "google-cloud-speech==2.34.0\n",
            "google-cloud-storage==3.7.0\n",
            "google-cloud-trace==1.17.0\n",
            "google-cloud-translate==3.23.0\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.7.1\n",
            "google-genai==1.55.0\n",
            "google-generativeai==0.8.5\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.8.0\n",
            "googleapis-common-protos==1.72.0\n",
            "googledrivedownloader==1.1.0\n",
            "gradio==5.50.0\n",
            "gradio_client==1.14.0\n",
            "graphviz==0.21\n",
            "greenlet==3.3.0\n",
            "groovy==0.1.2\n",
            "grpc-google-iam-v1==0.14.3\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.76.0\n",
            "grpcio-status==1.71.2\n",
            "grpclib==0.4.9\n",
            "gspread==6.2.1\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.1.0\n",
            "gymnasium==1.2.2\n",
            "h11==0.16.0\n",
            "h2==4.3.0\n",
            "h5netcdf==1.7.3\n",
            "h5py==3.15.1\n",
            "hdbscan==0.8.41\n",
            "hf-xet==1.2.0\n",
            "hf_transfer==0.1.9\n",
            "highspy==1.12.0\n",
            "holidays==0.86\n",
            "holoviews==1.22.1\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.9\n",
            "httpimport==1.4.1\n",
            "httplib2==0.31.0\n",
            "httpx==0.28.1\n",
            "httpx-sse==0.4.3\n",
            "huggingface-hub==0.36.0\n",
            "humanize==4.14.0\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.5.0\n",
            "idna==3.11\n",
            "ImageIO==2.37.2\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.14.0\n",
            "immutabledict==4.2.2\n",
            "importlib_metadata==8.7.0\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "inequality==1.1.2\n",
            "inflect==7.5.0\n",
            "iniconfig==2.3.0\n",
            "intel-cmplr-lib-ur==2025.3.1\n",
            "intel-openmp==2025.3.1\n",
            "ipyevents==2.0.4\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.20.0\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "isoduration==20.11.0\n",
            "itsdangerous==2.2.0\n",
            "jaraco.classes==3.4.0\n",
            "jaraco.context==6.0.1\n",
            "jaraco.functools==4.3.0\n",
            "jax==0.7.2\n",
            "jaxlib==0.7.2\n",
            "jeepney==0.9.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.6\n",
            "jiter==0.12.0\n",
            "joblib==1.5.3\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.1.1\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.25.1\n",
            "jsonschema-specifications==2025.9.1\n",
            "jupyter-console==6.6.3\n",
            "jupyter-events==0.12.0\n",
            "jupyter-leaflet==0.20.0\n",
            "jupyter_client==7.4.9\n",
            "jupyter_core==5.9.1\n",
            "jupyter_kernel_gateway @ git+https://github.com/googlecolab/kernel_gateway@b134e9945df25c2dcb98ade9129399be10788671\n",
            "jupyter_server==2.14.0\n",
            "jupyter_server_terminals==0.5.3\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.16\n",
            "jupytext==1.18.1\n",
            "kaggle==1.7.4.5\n",
            "kagglehub==0.3.13\n",
            "keras==3.10.0\n",
            "keras-hub==0.21.1\n",
            "keras-nlp==0.21.1\n",
            "keyring==25.7.0\n",
            "keyrings.google-artifactregistry-auth==1.1.2\n",
            "kiwisolver==1.4.9\n",
            "langchain==1.2.0\n",
            "langchain-core==1.2.1\n",
            "langgraph==1.0.5\n",
            "langgraph-checkpoint==3.0.1\n",
            "langgraph-prebuilt==1.0.5\n",
            "langgraph-sdk==0.3.0\n",
            "langsmith==0.4.59\n",
            "lark==1.3.1\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libpysal==4.13.0\n",
            "librosa==0.11.0\n",
            "lightgbm==4.6.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.7\n",
            "lxml==6.0.2\n",
            "Mako==1.3.10\n",
            "mapclassify==2.10.0\n",
            "Markdown==3.10\n",
            "markdown-it-py==4.0.0\n",
            "MarkupSafe==3.0.3\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.2.1\n",
            "matplotlib-venn==1.1.2\n",
            "mcp==1.24.0\n",
            "mdit-py-plugins==0.5.0\n",
            "mdurl==0.1.2\n",
            "mgwr==2.2.1\n",
            "miniKanren==1.0.5\n",
            "missingno==0.5.2\n",
            "mistune==3.1.4\n",
            "mizani==0.13.5\n",
            "mkl==2025.3.0\n",
            "ml_dtypes==0.5.4\n",
            "mlxtend==0.23.4\n",
            "mmh3==5.2.0\n",
            "momepy==0.10.0\n",
            "more-itertools==10.8.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.2\n",
            "multidict==6.7.0\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.16\n",
            "multitasking==0.0.12\n",
            "murmurhash==1.0.15\n",
            "music21==9.9.1\n",
            "namex==0.1.0\n",
            "narwhals==2.13.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.3.3\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.10.1\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.6.1\n",
            "nibabel==5.3.3\n",
            "nltk==3.9.1\n",
            "notebook==6.5.7\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numexpr==2.14.1\n",
            "numpy==2.0.2\n",
            "nvidia-nccl-cu12==2.28.9\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.3.1\n",
            "omegaconf==2.3.0\n",
            "onemkl-license==2025.3.0\n",
            "openai==2.12.0\n",
            "opencv-contrib-python==4.12.0.88\n",
            "opencv-python==4.12.0.88\n",
            "opencv-python-headless==4.12.0.88\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.37.0\n",
            "opentelemetry-exporter-gcp-logging==1.11.0a0\n",
            "opentelemetry-exporter-gcp-monitoring==1.11.0a0\n",
            "opentelemetry-exporter-gcp-trace==1.11.0\n",
            "opentelemetry-exporter-otlp-proto-common==1.37.0\n",
            "opentelemetry-exporter-otlp-proto-http==1.37.0\n",
            "opentelemetry-proto==1.37.0\n",
            "opentelemetry-resourcedetector-gcp==1.11.0a0\n",
            "opentelemetry-sdk==1.37.0\n",
            "opentelemetry-semantic-conventions==0.58b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.6\n",
            "optree==0.18.0\n",
            "orbax-checkpoint==0.11.31\n",
            "orjson==3.11.5\n",
            "ormsgpack==1.12.1\n",
            "osqp==1.0.5\n",
            "overrides==7.7.0\n",
            "packaging==25.0\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.30.0\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.8.4\n",
            "param==2.3.1\n",
            "parso==0.8.5\n",
            "parsy==2.2\n",
            "partd==1.4.2\n",
            "patsy==1.0.2\n",
            "peewee==3.18.3\n",
            "peft==0.18.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.3.0\n",
            "platformdirs==4.5.1\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.6.0\n",
            "plum-dispatch==2.6.0\n",
            "ply==3.11\n",
            "pointpats==2.5.2\n",
            "polars==1.31.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.12\n",
            "prettytable==3.17.0\n",
            "proglog==0.1.12\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.23.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.52\n",
            "propcache==0.4.1\n",
            "prophet==1.2.1\n",
            "proto-plus==1.26.1\n",
            "protobuf==5.29.5\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.11\n",
            "psygnal==0.15.0\n",
            "ptyprocess==0.7.0\n",
            "PuLP==3.3.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.9\n",
            "pyarrow==18.1.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.2\n",
            "pycairo==1.29.0\n",
            "pycocotools==2.0.10\n",
            "pycparser==2.23\n",
            "pycryptodomex==3.23.0\n",
            "pydantic==2.12.3\n",
            "pydantic-settings==2.12.0\n",
            "pydantic_core==2.41.4\n",
            "pydata-google-auth==1.9.1\n",
            "pydeck==0.9.1\n",
            "pydot==4.0.1\n",
            "pydotplus==2.0.2\n",
            "PyDrive2==1.21.3\n",
            "pydub==0.25.1\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.19.0\n",
            "Pygments==2.19.2\n",
            "PyGObject==3.48.2\n",
            "PyJWT==2.10.1\n",
            "pymc==5.26.1\n",
            "pynndescent==0.5.13\n",
            "pyogrio==0.12.1\n",
            "pyomo==6.9.5\n",
            "PyOpenGL==3.1.10\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.5\n",
            "pyperclip==1.11.0\n",
            "pyproj==3.7.2\n",
            "pysal==25.7\n",
            "pyshp==3.0.3\n",
            "PySocks==1.7.1\n",
            "pyspark==4.0.1\n",
            "pytensor==2.35.1\n",
            "pytest==8.4.2\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.9.0.post0\n",
            "python-dotenv==1.2.1\n",
            "python-json-logger==4.0.0\n",
            "python-louvain==0.16\n",
            "python-multipart==0.0.20\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.2\n",
            "pyviz_comms==3.0.6\n",
            "PyWavelets==1.9.0\n",
            "PyYAML==6.0.3\n",
            "pyzmq==26.2.1\n",
            "quantecon==0.10.1\n",
            "rasterio==1.4.4\n",
            "rasterstats==0.20.0\n",
            "ratelim==0.1.6\n",
            "referencing==0.37.0\n",
            "regex==2025.11.3\n",
            "requests==2.32.4\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rfc3339-validator==0.1.4\n",
            "rfc3986-validator==0.1.1\n",
            "rfc3987-syntax==1.1.0\n",
            "rich==13.9.4\n",
            "roman-numerals-py==3.1.0\n",
            "rpds-py==0.30.0\n",
            "rpy2==3.5.17\n",
            "rsa==4.9.1\n",
            "rtree==1.4.1\n",
            "ruff==0.14.9\n",
            "safehttpx==0.1.7\n",
            "safetensors==0.7.0\n",
            "scikit-image==0.25.2\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.16.3\n",
            "scooby==0.11.0\n",
            "scs==3.2.9\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.5.0\n",
            "segregation==2.5.3\n",
            "semantic-version==2.10.0\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==5.2.0\n",
            "sentencepiece==0.2.1\n",
            "sentry-sdk==2.47.0\n",
            "setuptools==75.2.0\n",
            "shap==0.50.0\n",
            "shapely==2.1.2\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.7\n",
            "simplejson==3.20.2\n",
            "simsimd==6.5.3\n",
            "six==1.17.0\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart_open==7.5.0\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==3.0.1\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.8\n",
            "soxr==1.0.0\n",
            "spacy==3.8.11\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spaghetti==1.7.6\n",
            "spanner-graph-notebook==1.1.8\n",
            "spglm==1.1.0\n",
            "Sphinx==8.2.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "spint==1.0.7\n",
            "splot==1.1.7\n",
            "spopt==0.7.0\n",
            "spreg==1.8.4\n",
            "SQLAlchemy==2.0.45\n",
            "sqlalchemy-spanner==1.17.1\n",
            "sqlglot==25.20.2\n",
            "sqlparse==0.5.4\n",
            "srsly==2.5.2\n",
            "sse-starlette==3.0.4\n",
            "stanio==0.5.1\n",
            "starlette==0.50.0\n",
            "statsmodels==0.14.6\n",
            "streamlit==1.52.2\n",
            "stringzilla==4.5.1\n",
            "stumpy==1.13.0\n",
            "sympy==1.14.0\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.3.0\n",
            "tcmlib==1.4.1\n",
            "tenacity==9.1.2\n",
            "tensorboard==2.19.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.19.0\n",
            "tensorflow-datasets==4.9.9\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-metadata==1.17.2\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.19.0\n",
            "tensorflow_decision_forests==1.12.0\n",
            "tensorstore==0.1.80\n",
            "termcolor==3.2.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.19.0\n",
            "thinc==8.3.10\n",
            "threadpoolctl==3.6.0\n",
            "tifffile==2025.12.12\n",
            "tiktoken==0.12.0\n",
            "timm==1.0.22\n",
            "tinycss2==1.4.0\n",
            "tobler==0.12.1\n",
            "tokenizers==0.22.1\n",
            "toml==0.10.2\n",
            "tomlkit==0.13.3\n",
            "toolz==0.12.1\n",
            "torch==2.9.0+cpu\n",
            "torchao==0.10.0\n",
            "torchaudio==2.9.0+cpu\n",
            "torchdata==0.11.0\n",
            "torchsummary==1.5.1\n",
            "torchtune==0.6.1\n",
            "torchvision==0.24.0+cpu\n",
            "tornado==6.5.1\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.3\n",
            "transformers==4.57.3\n",
            "treescope==0.1.10\n",
            "tsfresh==0.21.1\n",
            "tweepy==4.16.0\n",
            "typeguard==4.4.4\n",
            "typer==0.20.0\n",
            "typer-slim==0.20.0\n",
            "types-pytz==2025.2.0.20251108\n",
            "types-setuptools==80.9.0.20250822\n",
            "typing-inspection==0.4.2\n",
            "typing_extensions==4.15.0\n",
            "tzdata==2025.3\n",
            "tzlocal==5.3.1\n",
            "uc-micro-py==1.0.3\n",
            "umap-learn==0.5.9.post2\n",
            "umf==1.0.2\n",
            "uri-template==1.3.0\n",
            "uritemplate==4.2.0\n",
            "urllib3==2.5.0\n",
            "uuid_utils==0.12.0\n",
            "uvicorn==0.38.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.23.1\n",
            "wasabi==1.1.3\n",
            "watchdog==6.0.0\n",
            "wcwidth==0.2.14\n",
            "weasel==0.4.3\n",
            "webcolors==25.10.0\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.9.0\n",
            "websockets==15.0.1\n",
            "Werkzeug==3.1.4\n",
            "wheel==0.45.1\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==2.0.1\n",
            "wurlitzer==3.1.1\n",
            "xarray==2025.12.0\n",
            "xarray-einstats==0.9.1\n",
            "xgboost==3.1.2\n",
            "xlrd==2.0.2\n",
            "xxhash==3.6.0\n",
            "xyzservices==2025.11.0\n",
            "yarl==1.22.0\n",
            "ydf==0.13.0\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.66\n",
            "zipp==3.23.0\n",
            "zstandard==0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8dd70aa"
      },
      "source": [
        "## Prepare for Deployment to Streamlit Cloud\n",
        "\n",
        "### Subtask:\n",
        "Provide instructions on how to set up a GitHub repository with your `app.py` and `requirements.txt` files, and then deploy it to Streamlit Cloud.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3f7d044"
      },
      "source": [
        "## Prepare for Deployment to Streamlit Cloud\n",
        "\n",
        "### Subtask:\n",
        "Provide instructions on how to set up a GitHub repository with your `app.py` and `requirements.txt` files, and then deploy it to Streamlit Cloud.\n",
        "\n",
        "#### Instructions\n",
        "1.  **Create a GitHub Repository**: Initialize a new public GitHub repository. You can name it something descriptive, like 'mnist-streamlit-app'.\n",
        "2.  **Upload Files to GitHub**: Upload both `app.py` and `requirements.txt` files, along with the trained model file `mnist_cnn_model.h5`, to the root directory of your newly created GitHub repository. Ensure `mnist_cnn_model.h5` is also committed.\n",
        "3.  **Go to Streamlit Cloud**: Navigate to the Streamlit Cloud website (share.streamlit.io) and log in using your GitHub account.\n",
        "4.  **Deploy a New App**: Click on 'New app' (or 'Deploy an app' if it's your first time).\n",
        "5.  **Connect to GitHub**: Select your GitHub repository containing the Streamlit application. Make sure the branch (e.g., 'main' or 'master') and the main file path ('app.py') are correctly specified.\n",
        "6.  **Deploy the App**: Click 'Deploy!' to start the deployment process. Streamlit Cloud will automatically install the dependencies from `requirements.txt` and run your `app.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0840c5a7"
      },
      "source": [
        "## Prepare for Deployment to Streamlit Cloud\n",
        "\n",
        "### Subtask:\n",
        "Provide instructions on how to set up a GitHub repository with your `app.py` and `requirements.txt` files, and then deploy it to Streamlit Cloud.\n",
        "\n",
        "#### Instructions\n",
        "1.  **Create a GitHub Repository**: Initialize a new public GitHub repository. You can name it something descriptive, like 'mnist-streamlit-app'.\n",
        "2.  **Upload Files to GitHub**: Upload both `app.py` and `requirements.txt` files, along with the trained model file `mnist_cnn_model.h5`, to the root directory of your newly created GitHub repository. Ensure `mnist_cnn_model.h5` is also committed.\n",
        "3.  **Go to Streamlit Cloud**: Navigate to the Streamlit Cloud website (share.streamlit.io) and log in using your GitHub account.\n",
        "4.  **Deploy a New App**: Click on 'New app' (or 'Deploy an app' if it's your first time).\n",
        "5.  **Connect to GitHub**: Select your GitHub repository containing the Streamlit application. Make sure the branch (e.g., 'main' or 'master') and the main file path ('app.py') are correctly specified.\n",
        "6.  **Deploy the App**: Click 'Deploy!' to start the deployment process. Streamlit Cloud will automatically install the dependencies from `requirements.txt` and run your `app.py`.\n",
        "7.  **Verify Deployment**: Once the deployment is complete, Streamlit Cloud will provide a public URL for your application. Open this URL in your browser to verify that the app is running correctly and you can upload images for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc793121"
      },
      "source": [
        "## Prepare for Deployment to Streamlit Cloud\n",
        "\n",
        "### Subtask:\n",
        "Provide instructions on how to set up a GitHub repository with your `app.py` and `requirements.txt` files, and then deploy it to Streamlit Cloud.\n",
        "\n",
        "#### Instructions\n",
        "1.  **Create a GitHub Repository**: Initialize a new public GitHub repository. You can name it something descriptive, like 'mnist-streamlit-app'.\n",
        "2.  **Upload Files to GitHub**: Upload both `app.py` and `requirements.txt` files, along with the trained model file `mnist_cnn_model.h5`, to the root directory of your newly created GitHub repository. Ensure `mnist_cnn_model.h5` is also committed.\n",
        "3.  **Go to Streamlit Cloud**: Navigate to the Streamlit Cloud website (share.streamlit.io) and log in using your GitHub account.\n",
        "4.  **Deploy a New App**: Click on 'New app' (or 'Deploy an app' if it's your first time).\n",
        "5.  **Connect to GitHub**: Select your GitHub repository containing the Streamlit application. Make sure the branch (e.g., 'main' or 'master') and the main file path ('app.py') are correctly specified.\n",
        "6.  **Deploy the App**: Click 'Deploy!' to start the deployment process. Streamlit Cloud will automatically install the dependencies from `requirements.txt` and run your `app.py`.\n",
        "7.  **Verify Deployment**: Once the deployment is complete, Streamlit Cloud will provide a public URL for your application. Open this URL in your browser to verify that the app is running correctly and you can upload images for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad91aa81"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm the successful deployment of the application to Streamlit Cloud and provide a link to the deployed application if possible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5cca9d6"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A Streamlit application (`app.py`) was successfully created, integrating a previously trained CNN model for handwritten digit classification. This application handles image uploads, preprocessing (grayscale conversion, resizing to 28x28, normalization), and displays the predicted digit along with probabilities.\n",
        "*   The model used for the Streamlit application, `mnist_cnn_model.h5`, was successfully saved after redefining and retraining the CNN model due to an initial `NameError` during the model saving attempt.\n",
        "*   A `requirements.txt` file was generated, listing all necessary Python packages and their exact versions (e.g., `streamlit`, `tensorflow`, `numpy`, `pillow`), which is crucial for reproducible deployments.\n",
        "*   Comprehensive, step-by-step instructions for deploying the application to Streamlit Cloud were provided, detailing GitHub repository setup, file uploads (`app.py`, `requirements.txt`, `mnist_cnn_model.h5`), and the Streamlit Cloud deployment process.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The Streamlit application is now fully prepared for deployment, allowing for easy sharing and accessibility of the digit classification model through a user-friendly web interface.\n",
        "*   The next logical step is to execute the deployment instructions by setting up the GitHub repository and deploying the application to Streamlit Cloud, followed by thorough testing to confirm its functionality in the cloud environment.\n"
      ]
    }
  ]
}